{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c12e7fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/home/.cache/minigpt4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Blip2VisionConfig, Blip2VisionModel, AutoModelForImageClassification\n",
    "import copy, os, sys\n",
    "sys.path.append('../')\n",
    "from minigpt4.models.eva_vit import VisionTransformer, create_eva_vit_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aae4b01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incompatible_keys: \n",
      " _IncompatibleKeys(missing_keys=[], unexpected_keys=['norm.weight', 'norm.bias', 'head.weight', 'head.bias', 'blocks.39.norm1.weight', 'blocks.39.norm1.bias', 'blocks.39.attn.q_bias', 'blocks.39.attn.v_bias', 'blocks.39.attn.qkv.weight', 'blocks.39.attn.proj.weight', 'blocks.39.attn.proj.bias', 'blocks.39.norm2.weight', 'blocks.39.norm2.bias', 'blocks.39.mlp.fc1.weight', 'blocks.39.mlp.fc1.bias', 'blocks.39.mlp.fc2.weight', 'blocks.39.mlp.fc2.bias'])\n"
     ]
    }
   ],
   "source": [
    "mini_ve =  create_eva_vit_g(precision='fp32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51acebbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (blocks): ModuleList(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.010526316240429878)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.021052632480859756)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.031578950583934784)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.04210526496171951)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.05263157933950424)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.06315790116786957)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.0736842155456543)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.08421052992343903)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.09473684430122375)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.10526315867900848)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.11578948050737381)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (12): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.12631580233573914)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (13): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.13684210181236267)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (14): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.1473684310913086)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (15): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.15789474546909332)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (16): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.16842105984687805)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (17): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.17894737422466278)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (18): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.1894736886024475)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (19): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.20000001788139343)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (20): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.21052631735801697)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (21): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.2210526466369629)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (22): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.23157896101474762)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (23): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.24210527539253235)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (24): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.2526315748691559)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (25): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.2631579041481018)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (26): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.27368420362472534)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (27): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.28421053290367126)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (28): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.2947368323802948)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (29): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.3052631616592407)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (30): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.31578946113586426)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (31): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.3263157904148102)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (32): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.3368421196937561)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (33): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.34736841917037964)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (34): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.35789474844932556)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (35): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.3684210479259491)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (36): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.378947377204895)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (37): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.38947367668151855)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (38): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.4000000059604645)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_ve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3b97680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['q_bias', 'v_bias', 'qkv.weight', 'proj.weight', 'proj.bias'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_ve.blocks[0].attn.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "a120a464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 VisionTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (blocks): ModuleList(\n",
      "    (0): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.010526316240429878)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (2): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.021052632480859756)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (3): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.031578950583934784)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (4): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.04210526496171951)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (5): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.05263157933950424)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (6): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.06315790116786957)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (7): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.0736842155456543)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (8): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.08421052992343903)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (9): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.09473684430122375)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (10): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.10526315867900848)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (11): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.11578948050737381)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (12): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.12631580233573914)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (13): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.13684210181236267)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (14): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.1473684310913086)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (15): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.15789474546909332)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (16): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.16842105984687805)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (17): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.17894737422466278)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (18): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.1894736886024475)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (19): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.20000001788139343)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (20): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.21052631735801697)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (21): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.2210526466369629)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (22): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.23157896101474762)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (23): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.24210527539253235)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (24): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.2526315748691559)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (25): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.2631579041481018)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (26): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.27368420362472534)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (27): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.28421053290367126)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (28): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.2947368323802948)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (29): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.3052631616592407)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (30): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.31578946113586426)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (31): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.3263157904148102)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (32): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.3368421196937561)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (33): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.34736841917037964)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (34): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.35789474844932556)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (35): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.3684210479259491)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (36): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.378947377204895)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (37): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.38947367668151855)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (38): Block(\n",
      "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): DropPath(p=0.4000000059604645)\n",
      "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "        (act): GELU(approximate=none)\n",
      "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "1 PatchEmbed(\n",
      "  (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))\n",
      ")\n",
      "2 Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))\n",
      "3 Dropout(p=0.0, inplace=False)\n",
      "4 ModuleList(\n",
      "  (0): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.010526316240429878)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (2): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.021052632480859756)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (3): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.031578950583934784)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (4): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.04210526496171951)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (5): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.05263157933950424)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (6): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.06315790116786957)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (7): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.0736842155456543)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (8): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.08421052992343903)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (9): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.09473684430122375)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (10): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.10526315867900848)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (11): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.11578948050737381)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (12): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.12631580233573914)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (13): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.13684210181236267)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (14): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.1473684310913086)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (15): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.15789474546909332)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (16): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.16842105984687805)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (17): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.17894737422466278)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (18): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.1894736886024475)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (19): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.20000001788139343)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (20): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.21052631735801697)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (21): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.2210526466369629)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (22): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.23157896101474762)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (23): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.24210527539253235)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (24): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.2526315748691559)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (25): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.2631579041481018)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (26): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.27368420362472534)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (27): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.28421053290367126)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (28): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.2947368323802948)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (29): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.3052631616592407)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (30): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.31578946113586426)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (31): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.3263157904148102)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (32): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.3368421196937561)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (33): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.34736841917037964)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (34): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.35789474844932556)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (35): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.3684210479259491)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (36): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.378947377204895)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (37): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.38947367668151855)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (38): Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): DropPath(p=0.4000000059604645)\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate=none)\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "5 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "6 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "7 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "8 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "9 Dropout(p=0.0, inplace=False)\n",
      "10 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "11 Dropout(p=0.0, inplace=False)\n",
      "12 Identity()\n",
      "13 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "14 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "15 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "16 GELU(approximate=none)\n",
      "17 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "18 Dropout(p=0.0, inplace=False)\n",
      "19 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.010526316240429878)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "20 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "21 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "22 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "23 Dropout(p=0.0, inplace=False)\n",
      "24 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "25 Dropout(p=0.0, inplace=False)\n",
      "26 DropPath(p=0.010526316240429878)\n",
      "27 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "28 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "29 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "30 GELU(approximate=none)\n",
      "31 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "32 Dropout(p=0.0, inplace=False)\n",
      "33 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.021052632480859756)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "34 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "35 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "36 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "37 Dropout(p=0.0, inplace=False)\n",
      "38 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "39 Dropout(p=0.0, inplace=False)\n",
      "40 DropPath(p=0.021052632480859756)\n",
      "41 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "42 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "43 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "44 GELU(approximate=none)\n",
      "45 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "46 Dropout(p=0.0, inplace=False)\n",
      "47 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.031578950583934784)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "48 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "49 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "50 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "51 Dropout(p=0.0, inplace=False)\n",
      "52 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "53 Dropout(p=0.0, inplace=False)\n",
      "54 DropPath(p=0.031578950583934784)\n",
      "55 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "56 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "57 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "58 GELU(approximate=none)\n",
      "59 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "60 Dropout(p=0.0, inplace=False)\n",
      "61 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.04210526496171951)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "62 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "63 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "64 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "65 Dropout(p=0.0, inplace=False)\n",
      "66 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "67 Dropout(p=0.0, inplace=False)\n",
      "68 DropPath(p=0.04210526496171951)\n",
      "69 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "70 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "71 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "72 GELU(approximate=none)\n",
      "73 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "74 Dropout(p=0.0, inplace=False)\n",
      "75 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.05263157933950424)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "76 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "77 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "78 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "79 Dropout(p=0.0, inplace=False)\n",
      "80 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "81 Dropout(p=0.0, inplace=False)\n",
      "82 DropPath(p=0.05263157933950424)\n",
      "83 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "84 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "85 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "86 GELU(approximate=none)\n",
      "87 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "88 Dropout(p=0.0, inplace=False)\n",
      "89 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.06315790116786957)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "90 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "91 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "92 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "93 Dropout(p=0.0, inplace=False)\n",
      "94 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "95 Dropout(p=0.0, inplace=False)\n",
      "96 DropPath(p=0.06315790116786957)\n",
      "97 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "98 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "99 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "100 GELU(approximate=none)\n",
      "101 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "102 Dropout(p=0.0, inplace=False)\n",
      "103 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.0736842155456543)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "104 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "105 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "106 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "107 Dropout(p=0.0, inplace=False)\n",
      "108 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "109 Dropout(p=0.0, inplace=False)\n",
      "110 DropPath(p=0.0736842155456543)\n",
      "111 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "112 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "113 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "114 GELU(approximate=none)\n",
      "115 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "116 Dropout(p=0.0, inplace=False)\n",
      "117 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.08421052992343903)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "118 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "119 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "120 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "121 Dropout(p=0.0, inplace=False)\n",
      "122 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "123 Dropout(p=0.0, inplace=False)\n",
      "124 DropPath(p=0.08421052992343903)\n",
      "125 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "126 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "127 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "128 GELU(approximate=none)\n",
      "129 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "130 Dropout(p=0.0, inplace=False)\n",
      "131 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.09473684430122375)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "132 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "133 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "134 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "135 Dropout(p=0.0, inplace=False)\n",
      "136 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "137 Dropout(p=0.0, inplace=False)\n",
      "138 DropPath(p=0.09473684430122375)\n",
      "139 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "140 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "141 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "142 GELU(approximate=none)\n",
      "143 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "144 Dropout(p=0.0, inplace=False)\n",
      "145 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.10526315867900848)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "146 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "147 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "148 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "149 Dropout(p=0.0, inplace=False)\n",
      "150 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "151 Dropout(p=0.0, inplace=False)\n",
      "152 DropPath(p=0.10526315867900848)\n",
      "153 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "154 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "155 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "156 GELU(approximate=none)\n",
      "157 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "158 Dropout(p=0.0, inplace=False)\n",
      "159 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.11578948050737381)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "160 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "161 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "162 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "163 Dropout(p=0.0, inplace=False)\n",
      "164 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "165 Dropout(p=0.0, inplace=False)\n",
      "166 DropPath(p=0.11578948050737381)\n",
      "167 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "168 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "169 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "170 GELU(approximate=none)\n",
      "171 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "172 Dropout(p=0.0, inplace=False)\n",
      "173 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.12631580233573914)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "174 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "175 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "176 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "177 Dropout(p=0.0, inplace=False)\n",
      "178 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "179 Dropout(p=0.0, inplace=False)\n",
      "180 DropPath(p=0.12631580233573914)\n",
      "181 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "182 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "183 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "184 GELU(approximate=none)\n",
      "185 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "186 Dropout(p=0.0, inplace=False)\n",
      "187 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.13684210181236267)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "188 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "189 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "190 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "191 Dropout(p=0.0, inplace=False)\n",
      "192 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "193 Dropout(p=0.0, inplace=False)\n",
      "194 DropPath(p=0.13684210181236267)\n",
      "195 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "196 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "197 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "198 GELU(approximate=none)\n",
      "199 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "200 Dropout(p=0.0, inplace=False)\n",
      "201 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.1473684310913086)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "202 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "203 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "204 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "205 Dropout(p=0.0, inplace=False)\n",
      "206 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "207 Dropout(p=0.0, inplace=False)\n",
      "208 DropPath(p=0.1473684310913086)\n",
      "209 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "210 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "211 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "212 GELU(approximate=none)\n",
      "213 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "214 Dropout(p=0.0, inplace=False)\n",
      "215 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.15789474546909332)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "216 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "217 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "218 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "219 Dropout(p=0.0, inplace=False)\n",
      "220 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "221 Dropout(p=0.0, inplace=False)\n",
      "222 DropPath(p=0.15789474546909332)\n",
      "223 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "224 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "225 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "226 GELU(approximate=none)\n",
      "227 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "228 Dropout(p=0.0, inplace=False)\n",
      "229 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.16842105984687805)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "230 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "231 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "232 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "233 Dropout(p=0.0, inplace=False)\n",
      "234 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "235 Dropout(p=0.0, inplace=False)\n",
      "236 DropPath(p=0.16842105984687805)\n",
      "237 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "238 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "239 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "240 GELU(approximate=none)\n",
      "241 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "242 Dropout(p=0.0, inplace=False)\n",
      "243 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.17894737422466278)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "244 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "245 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "246 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "247 Dropout(p=0.0, inplace=False)\n",
      "248 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "249 Dropout(p=0.0, inplace=False)\n",
      "250 DropPath(p=0.17894737422466278)\n",
      "251 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "252 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "253 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "254 GELU(approximate=none)\n",
      "255 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "256 Dropout(p=0.0, inplace=False)\n",
      "257 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.1894736886024475)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "258 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "259 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "260 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "261 Dropout(p=0.0, inplace=False)\n",
      "262 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "263 Dropout(p=0.0, inplace=False)\n",
      "264 DropPath(p=0.1894736886024475)\n",
      "265 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "266 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "267 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "268 GELU(approximate=none)\n",
      "269 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "270 Dropout(p=0.0, inplace=False)\n",
      "271 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.20000001788139343)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "272 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "273 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "274 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "275 Dropout(p=0.0, inplace=False)\n",
      "276 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "277 Dropout(p=0.0, inplace=False)\n",
      "278 DropPath(p=0.20000001788139343)\n",
      "279 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "280 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "281 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "282 GELU(approximate=none)\n",
      "283 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "284 Dropout(p=0.0, inplace=False)\n",
      "285 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.21052631735801697)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "286 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "287 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "288 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "289 Dropout(p=0.0, inplace=False)\n",
      "290 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "291 Dropout(p=0.0, inplace=False)\n",
      "292 DropPath(p=0.21052631735801697)\n",
      "293 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "294 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "295 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "296 GELU(approximate=none)\n",
      "297 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "298 Dropout(p=0.0, inplace=False)\n",
      "299 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.2210526466369629)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "300 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "301 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "302 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "303 Dropout(p=0.0, inplace=False)\n",
      "304 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "305 Dropout(p=0.0, inplace=False)\n",
      "306 DropPath(p=0.2210526466369629)\n",
      "307 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "308 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "309 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "310 GELU(approximate=none)\n",
      "311 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "312 Dropout(p=0.0, inplace=False)\n",
      "313 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.23157896101474762)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "314 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "315 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "316 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "317 Dropout(p=0.0, inplace=False)\n",
      "318 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "319 Dropout(p=0.0, inplace=False)\n",
      "320 DropPath(p=0.23157896101474762)\n",
      "321 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "322 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "323 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "324 GELU(approximate=none)\n",
      "325 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "326 Dropout(p=0.0, inplace=False)\n",
      "327 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.24210527539253235)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "328 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "329 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "330 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "331 Dropout(p=0.0, inplace=False)\n",
      "332 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "333 Dropout(p=0.0, inplace=False)\n",
      "334 DropPath(p=0.24210527539253235)\n",
      "335 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "336 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "337 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "338 GELU(approximate=none)\n",
      "339 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "340 Dropout(p=0.0, inplace=False)\n",
      "341 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.2526315748691559)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "342 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "343 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "344 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "345 Dropout(p=0.0, inplace=False)\n",
      "346 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "347 Dropout(p=0.0, inplace=False)\n",
      "348 DropPath(p=0.2526315748691559)\n",
      "349 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "350 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "351 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "352 GELU(approximate=none)\n",
      "353 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "354 Dropout(p=0.0, inplace=False)\n",
      "355 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.2631579041481018)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "356 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "357 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "358 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "359 Dropout(p=0.0, inplace=False)\n",
      "360 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "361 Dropout(p=0.0, inplace=False)\n",
      "362 DropPath(p=0.2631579041481018)\n",
      "363 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "364 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "365 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "366 GELU(approximate=none)\n",
      "367 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "368 Dropout(p=0.0, inplace=False)\n",
      "369 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.27368420362472534)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "370 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "371 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "372 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "373 Dropout(p=0.0, inplace=False)\n",
      "374 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "375 Dropout(p=0.0, inplace=False)\n",
      "376 DropPath(p=0.27368420362472534)\n",
      "377 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "378 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "379 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "380 GELU(approximate=none)\n",
      "381 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "382 Dropout(p=0.0, inplace=False)\n",
      "383 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.28421053290367126)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "384 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "385 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "386 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "387 Dropout(p=0.0, inplace=False)\n",
      "388 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "389 Dropout(p=0.0, inplace=False)\n",
      "390 DropPath(p=0.28421053290367126)\n",
      "391 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "392 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "393 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "394 GELU(approximate=none)\n",
      "395 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "396 Dropout(p=0.0, inplace=False)\n",
      "397 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.2947368323802948)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "398 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "399 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "400 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "401 Dropout(p=0.0, inplace=False)\n",
      "402 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "403 Dropout(p=0.0, inplace=False)\n",
      "404 DropPath(p=0.2947368323802948)\n",
      "405 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "406 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "407 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "408 GELU(approximate=none)\n",
      "409 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "410 Dropout(p=0.0, inplace=False)\n",
      "411 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.3052631616592407)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "412 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "413 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "414 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "415 Dropout(p=0.0, inplace=False)\n",
      "416 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "417 Dropout(p=0.0, inplace=False)\n",
      "418 DropPath(p=0.3052631616592407)\n",
      "419 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "420 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "421 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "422 GELU(approximate=none)\n",
      "423 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "424 Dropout(p=0.0, inplace=False)\n",
      "425 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.31578946113586426)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "426 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "427 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "428 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "429 Dropout(p=0.0, inplace=False)\n",
      "430 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "431 Dropout(p=0.0, inplace=False)\n",
      "432 DropPath(p=0.31578946113586426)\n",
      "433 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "434 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "435 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "436 GELU(approximate=none)\n",
      "437 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "438 Dropout(p=0.0, inplace=False)\n",
      "439 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.3263157904148102)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "440 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "441 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "442 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "443 Dropout(p=0.0, inplace=False)\n",
      "444 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "445 Dropout(p=0.0, inplace=False)\n",
      "446 DropPath(p=0.3263157904148102)\n",
      "447 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "448 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "449 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "450 GELU(approximate=none)\n",
      "451 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "452 Dropout(p=0.0, inplace=False)\n",
      "453 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.3368421196937561)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "454 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "455 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "456 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "457 Dropout(p=0.0, inplace=False)\n",
      "458 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "459 Dropout(p=0.0, inplace=False)\n",
      "460 DropPath(p=0.3368421196937561)\n",
      "461 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "462 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "463 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "464 GELU(approximate=none)\n",
      "465 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "466 Dropout(p=0.0, inplace=False)\n",
      "467 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.34736841917037964)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "468 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "469 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "470 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "471 Dropout(p=0.0, inplace=False)\n",
      "472 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "473 Dropout(p=0.0, inplace=False)\n",
      "474 DropPath(p=0.34736841917037964)\n",
      "475 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "476 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "477 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "478 GELU(approximate=none)\n",
      "479 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "480 Dropout(p=0.0, inplace=False)\n",
      "481 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.35789474844932556)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "482 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "483 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "484 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "485 Dropout(p=0.0, inplace=False)\n",
      "486 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "487 Dropout(p=0.0, inplace=False)\n",
      "488 DropPath(p=0.35789474844932556)\n",
      "489 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "490 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "491 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "492 GELU(approximate=none)\n",
      "493 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "494 Dropout(p=0.0, inplace=False)\n",
      "495 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.3684210479259491)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "496 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "497 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "498 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "499 Dropout(p=0.0, inplace=False)\n",
      "500 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "501 Dropout(p=0.0, inplace=False)\n",
      "502 DropPath(p=0.3684210479259491)\n",
      "503 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "504 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "505 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "506 GELU(approximate=none)\n",
      "507 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "508 Dropout(p=0.0, inplace=False)\n",
      "509 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.378947377204895)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "510 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "511 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "512 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "513 Dropout(p=0.0, inplace=False)\n",
      "514 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "515 Dropout(p=0.0, inplace=False)\n",
      "516 DropPath(p=0.378947377204895)\n",
      "517 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "518 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "519 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "520 GELU(approximate=none)\n",
      "521 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "522 Dropout(p=0.0, inplace=False)\n",
      "523 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.38947367668151855)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "524 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "525 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "526 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "527 Dropout(p=0.0, inplace=False)\n",
      "528 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "529 Dropout(p=0.0, inplace=False)\n",
      "530 DropPath(p=0.38947367668151855)\n",
      "531 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "532 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "533 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "534 GELU(approximate=none)\n",
      "535 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "536 Dropout(p=0.0, inplace=False)\n",
      "537 Block(\n",
      "  (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (attn): Attention(\n",
      "    (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "    (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "    (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "    (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (drop_path): DropPath(p=0.4000000059604645)\n",
      "  (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "  (mlp): Mlp(\n",
      "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "    (act): GELU(approximate=none)\n",
      "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      ")\n",
      "538 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "539 Attention(\n",
      "  (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "  (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "540 Linear(in_features=1408, out_features=4224, bias=False)\n",
      "541 Dropout(p=0.0, inplace=False)\n",
      "542 Linear(in_features=1408, out_features=1408, bias=True)\n",
      "543 Dropout(p=0.0, inplace=False)\n",
      "544 DropPath(p=0.4000000059604645)\n",
      "545 LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "546 Mlp(\n",
      "  (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "  (act): GELU(approximate=none)\n",
      "  (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "  (drop): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "547 Linear(in_features=1408, out_features=6144, bias=True)\n",
      "548 GELU(approximate=none)\n",
      "549 Linear(in_features=6144, out_features=1408, bias=True)\n",
      "550 Dropout(p=0.0, inplace=False)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for x in mini_ve.modules():\n",
    "    print(f'{i} {x}')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "d52743b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.modules at 0x7fc0bc0aa580>"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfc6be6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53a46943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): VisionTransformer(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))\n",
       "      )\n",
       "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "      (blocks): ModuleList(\n",
       "        (0): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.010526316240429878)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.021052632480859756)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.031578950583934784)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.04210526496171951)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.05263157933950424)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.06315790116786957)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.0736842155456543)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.08421052992343903)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.09473684430122375)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.10526315867900848)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.11578948050737381)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.12631580233573914)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.13684210181236267)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.1473684310913086)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.15789474546909332)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.16842105984687805)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.17894737422466278)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.1894736886024475)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.20000001788139343)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.21052631735801697)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.2210526466369629)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.23157896101474762)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.24210527539253235)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (24): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.2526315748691559)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (25): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.2631579041481018)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (26): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.27368420362472534)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (27): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.28421053290367126)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (28): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.2947368323802948)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (29): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.3052631616592407)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (30): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.31578946113586426)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (31): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.3263157904148102)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (32): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.3368421196937561)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (33): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.34736841917037964)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (34): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.35789474844932556)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (35): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.3684210479259491)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (36): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.378947377204895)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (37): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.38947367668151855)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (38): Block(\n",
       "          (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(\n",
       "              in_features=1408, out_features=4224, bias=False\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=1408, out_features=16, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=16, out_features=4224, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): DropPath(p=0.4000000059604645)\n",
       "          (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (act): GELU(approximate=none)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f7f99f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test for qkv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "3a97d0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 5\n",
    "qkv = torch.nn.Linear(dim, dim*3).eval()\n",
    "lq = torch.nn.Linear(dim, dim).eval()\n",
    "lk = torch.nn.Linear(dim, dim).eval()\n",
    "lv = torch.nn.Linear(dim, dim).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "f4030428",
   "metadata": {},
   "outputs": [],
   "source": [
    "lq.weight = torch.nn.Parameter(qkv.weight[0:dim,:])\n",
    "lk.weight = torch.nn.Parameter(qkv.weight[dim:2*dim,:])\n",
    "lv.weight = torch.nn.Parameter(qkv.weight[2*dim:3*dim,:])\n",
    "\n",
    "lq.bias = torch.nn.Parameter(qkv.bias[0:dim])\n",
    "lk.bias = torch.nn.Parameter(qkv.bias[dim:2*dim])\n",
    "lv.bias = torch.nn.Parameter(qkv.bias[2*dim:3*dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "e89a2364",
   "metadata": {},
   "outputs": [],
   "source": [
    "lq.weight.data = qkv.weight.data[0:dim,:]\n",
    "lk.weight.data = qkv.weight.data[dim:2*dim,:]\n",
    "lv.weight.data = qkv.weight.data[2*dim:3*dim,:]\n",
    "\n",
    "lq.bias.data = qkv.bias.data[0:dim]\n",
    "lk.bias.data = qkv.bias.data[dim:2*dim]\n",
    "lv.bias.data = qkv.bias.data[2*dim:3*dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c09729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "39ea2fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test = torch.randn([1,3,dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "aa5d4906",
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv_out = qkv(input_test)\n",
    "lq_out = lq(input_test)\n",
    "lk_out = lk(input_test)\n",
    "lv_out = lv(input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "b3ed5764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 15])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "d7555901",
   "metadata": {},
   "outputs": [],
   "source": [
    "fqkv_out = torch.cat([lq_out,lk_out,lv_out], dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "5ead1766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-7.6996e-01, -6.1207e-02,  2.9218e-01,  9.5623e-01,  9.5634e-01,\n",
       "           6.0143e-01,  5.0327e-01, -8.3091e-01,  1.3538e-02,  5.8970e-01,\n",
       "           7.5116e-01,  5.2686e-01, -1.4199e+00,  7.1408e-01, -1.2708e+00],\n",
       "         [-1.0409e+00,  3.5706e-01,  7.7207e-01, -8.1972e-03,  4.5232e-01,\n",
       "           1.1576e+00,  1.5320e+00, -1.3131e-01,  5.9755e-01,  6.8769e-01,\n",
       "           3.9372e-01,  1.1992e-03, -1.5298e+00,  1.0866e+00, -1.4098e+00],\n",
       "         [-6.7180e-01, -6.0535e-01,  2.3557e-01,  7.7827e-01,  2.1809e-02,\n",
       "          -3.3447e-01, -2.1217e-01,  3.9364e-01,  2.0960e-02,  2.5075e-01,\n",
       "          -9.0930e-01,  7.5032e-01,  4.8156e-01,  2.4848e-01,  4.3870e-01]]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fqkv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "4c3458d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-7.6996e-01, -6.1207e-02,  2.9218e-01,  9.5623e-01,  9.5634e-01,\n",
       "           6.0143e-01,  5.0327e-01, -8.3091e-01,  1.3538e-02,  5.8970e-01,\n",
       "           7.5116e-01,  5.2686e-01, -1.4199e+00,  7.1408e-01, -1.2708e+00],\n",
       "         [-1.0409e+00,  3.5706e-01,  7.7207e-01, -8.1972e-03,  4.5232e-01,\n",
       "           1.1576e+00,  1.5320e+00, -1.3131e-01,  5.9755e-01,  6.8769e-01,\n",
       "           3.9372e-01,  1.1992e-03, -1.5298e+00,  1.0866e+00, -1.4098e+00],\n",
       "         [-6.7180e-01, -6.0535e-01,  2.3557e-01,  7.7827e-01,  2.1809e-02,\n",
       "          -3.3447e-01, -2.1216e-01,  3.9364e-01,  2.0960e-02,  2.5075e-01,\n",
       "          -9.0930e-01,  7.5032e-01,  4.8156e-01,  2.4848e-01,  4.3870e-01]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "03d9e77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1921e-07, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(fqkv_out - qkv_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "38d7207d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82b81a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 100])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lq.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2facc2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True]]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5d3811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5b7c515",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minigpt4.models.eva_vit_sparse_qkv import create_eva_vit_g_sparse_qkv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5e0b2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incompatible_keys: \n",
      " _IncompatibleKeys(missing_keys=[], unexpected_keys=['norm.weight', 'norm.bias', 'head.weight', 'head.bias', 'blocks.39.norm1.weight', 'blocks.39.norm1.bias', 'blocks.39.attn.q_bias', 'blocks.39.attn.v_bias', 'blocks.39.attn.qkv.weight', 'blocks.39.attn.proj.weight', 'blocks.39.attn.proj.bias', 'blocks.39.norm2.weight', 'blocks.39.norm2.bias', 'blocks.39.mlp.fc1.weight', 'blocks.39.mlp.fc1.bias', 'blocks.39.mlp.fc2.weight', 'blocks.39.mlp.fc2.bias'])\n",
      "incompatible_keys: \n",
      " _IncompatibleKeys(missing_keys=['blocks.0.attn.query.weight', 'blocks.0.attn.key.weight', 'blocks.0.attn.value.weight', 'blocks.1.attn.query.weight', 'blocks.1.attn.key.weight', 'blocks.1.attn.value.weight', 'blocks.2.attn.query.weight', 'blocks.2.attn.key.weight', 'blocks.2.attn.value.weight', 'blocks.3.attn.query.weight', 'blocks.3.attn.key.weight', 'blocks.3.attn.value.weight', 'blocks.4.attn.query.weight', 'blocks.4.attn.key.weight', 'blocks.4.attn.value.weight', 'blocks.5.attn.query.weight', 'blocks.5.attn.key.weight', 'blocks.5.attn.value.weight', 'blocks.6.attn.query.weight', 'blocks.6.attn.key.weight', 'blocks.6.attn.value.weight', 'blocks.7.attn.query.weight', 'blocks.7.attn.key.weight', 'blocks.7.attn.value.weight', 'blocks.8.attn.query.weight', 'blocks.8.attn.key.weight', 'blocks.8.attn.value.weight', 'blocks.9.attn.query.weight', 'blocks.9.attn.key.weight', 'blocks.9.attn.value.weight', 'blocks.10.attn.query.weight', 'blocks.10.attn.key.weight', 'blocks.10.attn.value.weight', 'blocks.11.attn.query.weight', 'blocks.11.attn.key.weight', 'blocks.11.attn.value.weight', 'blocks.12.attn.query.weight', 'blocks.12.attn.key.weight', 'blocks.12.attn.value.weight', 'blocks.13.attn.query.weight', 'blocks.13.attn.key.weight', 'blocks.13.attn.value.weight', 'blocks.14.attn.query.weight', 'blocks.14.attn.key.weight', 'blocks.14.attn.value.weight', 'blocks.15.attn.query.weight', 'blocks.15.attn.key.weight', 'blocks.15.attn.value.weight', 'blocks.16.attn.query.weight', 'blocks.16.attn.key.weight', 'blocks.16.attn.value.weight', 'blocks.17.attn.query.weight', 'blocks.17.attn.key.weight', 'blocks.17.attn.value.weight', 'blocks.18.attn.query.weight', 'blocks.18.attn.key.weight', 'blocks.18.attn.value.weight', 'blocks.19.attn.query.weight', 'blocks.19.attn.key.weight', 'blocks.19.attn.value.weight', 'blocks.20.attn.query.weight', 'blocks.20.attn.key.weight', 'blocks.20.attn.value.weight', 'blocks.21.attn.query.weight', 'blocks.21.attn.key.weight', 'blocks.21.attn.value.weight', 'blocks.22.attn.query.weight', 'blocks.22.attn.key.weight', 'blocks.22.attn.value.weight', 'blocks.23.attn.query.weight', 'blocks.23.attn.key.weight', 'blocks.23.attn.value.weight', 'blocks.24.attn.query.weight', 'blocks.24.attn.key.weight', 'blocks.24.attn.value.weight', 'blocks.25.attn.query.weight', 'blocks.25.attn.key.weight', 'blocks.25.attn.value.weight', 'blocks.26.attn.query.weight', 'blocks.26.attn.key.weight', 'blocks.26.attn.value.weight', 'blocks.27.attn.query.weight', 'blocks.27.attn.key.weight', 'blocks.27.attn.value.weight', 'blocks.28.attn.query.weight', 'blocks.28.attn.key.weight', 'blocks.28.attn.value.weight', 'blocks.29.attn.query.weight', 'blocks.29.attn.key.weight', 'blocks.29.attn.value.weight', 'blocks.30.attn.query.weight', 'blocks.30.attn.key.weight', 'blocks.30.attn.value.weight', 'blocks.31.attn.query.weight', 'blocks.31.attn.key.weight', 'blocks.31.attn.value.weight', 'blocks.32.attn.query.weight', 'blocks.32.attn.key.weight', 'blocks.32.attn.value.weight', 'blocks.33.attn.query.weight', 'blocks.33.attn.key.weight', 'blocks.33.attn.value.weight', 'blocks.34.attn.query.weight', 'blocks.34.attn.key.weight', 'blocks.34.attn.value.weight', 'blocks.35.attn.query.weight', 'blocks.35.attn.key.weight', 'blocks.35.attn.value.weight', 'blocks.36.attn.query.weight', 'blocks.36.attn.key.weight', 'blocks.36.attn.value.weight', 'blocks.37.attn.query.weight', 'blocks.37.attn.key.weight', 'blocks.37.attn.value.weight', 'blocks.38.attn.query.weight', 'blocks.38.attn.key.weight', 'blocks.38.attn.value.weight'], unexpected_keys=['norm.weight', 'norm.bias', 'head.weight', 'head.bias', 'blocks.39.norm1.weight', 'blocks.39.norm1.bias', 'blocks.39.attn.q_bias', 'blocks.39.attn.v_bias', 'blocks.39.attn.qkv.weight', 'blocks.39.attn.proj.weight', 'blocks.39.attn.proj.bias', 'blocks.39.norm2.weight', 'blocks.39.norm2.bias', 'blocks.39.mlp.fc1.weight', 'blocks.39.mlp.fc1.bias', 'blocks.39.mlp.fc2.weight', 'blocks.39.mlp.fc2.bias'])\n",
      "split qkv for blocks.0.attn\n",
      "split qkv for blocks.1.attn\n",
      "split qkv for blocks.2.attn\n",
      "split qkv for blocks.3.attn\n",
      "split qkv for blocks.4.attn\n",
      "split qkv for blocks.5.attn\n",
      "split qkv for blocks.6.attn\n",
      "split qkv for blocks.7.attn\n",
      "split qkv for blocks.8.attn\n",
      "split qkv for blocks.9.attn\n",
      "split qkv for blocks.10.attn\n",
      "split qkv for blocks.11.attn\n",
      "split qkv for blocks.12.attn\n",
      "split qkv for blocks.13.attn\n",
      "split qkv for blocks.14.attn\n",
      "split qkv for blocks.15.attn\n",
      "split qkv for blocks.16.attn\n",
      "split qkv for blocks.17.attn\n",
      "split qkv for blocks.18.attn\n",
      "split qkv for blocks.19.attn\n",
      "split qkv for blocks.20.attn\n",
      "split qkv for blocks.21.attn\n",
      "split qkv for blocks.22.attn\n",
      "split qkv for blocks.23.attn\n",
      "split qkv for blocks.24.attn\n",
      "split qkv for blocks.25.attn\n",
      "split qkv for blocks.26.attn\n",
      "split qkv for blocks.27.attn\n",
      "split qkv for blocks.28.attn\n",
      "split qkv for blocks.29.attn\n",
      "split qkv for blocks.30.attn\n",
      "split qkv for blocks.31.attn\n",
      "split qkv for blocks.32.attn\n",
      "split qkv for blocks.33.attn\n",
      "split qkv for blocks.34.attn\n",
      "split qkv for blocks.35.attn\n",
      "split qkv for blocks.36.attn\n",
      "split qkv for blocks.37.attn\n",
      "split qkv for blocks.38.attn\n"
     ]
    }
   ],
   "source": [
    "mini_ve =  create_eva_vit_g(precision='fp32')\n",
    "s_mini_ve = create_eva_vit_g_sparse_qkv(precision='fp32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae536345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6cb66bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_ve.eval()\n",
    "s_mini_ve.eval()\n",
    "input_image = torch.randn([1,3,224,224])\n",
    "out_ns = mini_ve(input_image)\n",
    "out_s = s_mini_ve(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7eb90c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(out_ns - out_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5ece4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "False in (out_ns == out_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5524dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6130,  0.3576,  0.4530,  ...,  0.0764, -2.6244,  1.3055],\n",
       "         [ 0.5288,  1.2078,  0.2100,  ...,  0.9368, -0.4550,  0.4996],\n",
       "         [ 0.3802,  1.0288,  0.6383,  ...,  0.6912, -0.3559, -0.1243],\n",
       "         ...,\n",
       "         [ 0.6755,  0.5917,  0.6956,  ...,  1.9820, -0.6884,  0.6076],\n",
       "         [ 1.0455,  1.5453,  0.8666,  ...,  0.1916, -0.4121,  0.2025],\n",
       "         [ 0.9976,  0.6633,  0.8597,  ...,  1.1618, -0.0878,  1.3839]],\n",
       "\n",
       "        [[ 0.6146,  0.2851,  0.4449,  ...,  0.1012, -2.6816,  1.4402],\n",
       "         [ 0.6663,  0.6814,  0.5441,  ...,  1.0736, -0.1627,  1.3004],\n",
       "         [-0.1694,  0.8392,  0.5206,  ...,  0.9756, -0.2034,  0.5643],\n",
       "         ...,\n",
       "         [ 0.7379,  1.3083,  0.3780,  ...,  1.1864,  0.3446, -0.5274],\n",
       "         [ 0.4539,  1.5651,  0.8978,  ...,  1.4355,  0.4208,  0.7676],\n",
       "         [ 1.0197,  0.7783,  0.9767,  ...,  1.0601, -0.0200,  1.6157]],\n",
       "\n",
       "        [[ 0.7601,  0.2384,  0.4656,  ...,  0.1436, -2.8049,  1.5256],\n",
       "         [ 0.4584,  0.8854,  0.0455,  ...,  0.9012, -0.2557,  1.1028],\n",
       "         [ 1.0911,  0.8583,  1.6903,  ...,  0.1907, -0.5678,  0.2351],\n",
       "         ...,\n",
       "         [ 0.8484,  0.4513,  0.7342,  ...,  1.9730, -0.8744,  0.7713],\n",
       "         [ 1.4711,  1.6639,  0.4931,  ...,  1.3625,  0.3331, -0.1416],\n",
       "         [ 0.9731,  0.9428,  0.7225,  ...,  1.0549, -0.0343,  1.3479]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f74a7590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6130,  0.3576,  0.4530,  ...,  0.0764, -2.6244,  1.3055],\n",
       "         [ 0.5288,  1.2078,  0.2100,  ...,  0.9368, -0.4550,  0.4996],\n",
       "         [ 0.3802,  1.0288,  0.6383,  ...,  0.6912, -0.3559, -0.1243],\n",
       "         ...,\n",
       "         [ 0.6755,  0.5917,  0.6956,  ...,  1.9820, -0.6884,  0.6076],\n",
       "         [ 1.0455,  1.5453,  0.8666,  ...,  0.1916, -0.4121,  0.2025],\n",
       "         [ 0.9976,  0.6633,  0.8597,  ...,  1.1618, -0.0878,  1.3839]],\n",
       "\n",
       "        [[ 0.6146,  0.2851,  0.4449,  ...,  0.1012, -2.6816,  1.4402],\n",
       "         [ 0.6663,  0.6814,  0.5441,  ...,  1.0736, -0.1627,  1.3004],\n",
       "         [-0.1694,  0.8392,  0.5206,  ...,  0.9756, -0.2034,  0.5643],\n",
       "         ...,\n",
       "         [ 0.7379,  1.3083,  0.3780,  ...,  1.1864,  0.3446, -0.5274],\n",
       "         [ 0.4539,  1.5651,  0.8978,  ...,  1.4355,  0.4208,  0.7676],\n",
       "         [ 1.0197,  0.7783,  0.9767,  ...,  1.0601, -0.0200,  1.6157]],\n",
       "\n",
       "        [[ 0.7601,  0.2384,  0.4656,  ...,  0.1436, -2.8049,  1.5256],\n",
       "         [ 0.4584,  0.8854,  0.0455,  ...,  0.9012, -0.2557,  1.1028],\n",
       "         [ 1.0911,  0.8583,  1.6903,  ...,  0.1907, -0.5678,  0.2351],\n",
       "         ...,\n",
       "         [ 0.8484,  0.4513,  0.7342,  ...,  1.9730, -0.8744,  0.7713],\n",
       "         [ 1.4711,  1.6639,  0.4931,  ...,  1.3625,  0.3331, -0.1416],\n",
       "         [ 0.9731,  0.9428,  0.7225,  ...,  1.0549, -0.0343,  1.3479]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2da91c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_config, get_peft_model\n",
    "s_mini_ve.config = None\n",
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=['query','key'],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    modules_to_save=[\"classifier\"],\n",
    ")\n",
    "lora_model = get_peft_model(s_mini_ve, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1215b291",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7824593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1408, 16])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_model.base_model.blocks[0].attn.query.lora_B.default.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "024986c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_ve.eval()\n",
    "lora_model.eval()\n",
    "input_image = torch.randn([1,3,224,224])\n",
    "out_ns = mini_ve(input_image)\n",
    "out_s = s_mini_ve(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09c6b452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(out_ns - out_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d395c9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "False in (out_ns == out_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3900f7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 257, 1408])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_ns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa116afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "361856"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "257*1408"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a259fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d460065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (blocks): ModuleList(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.010526316240429878)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.021052632480859756)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.031578950583934784)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.04210526496171951)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.05263157933950424)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.06315790116786957)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.0736842155456543)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.08421052992343903)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.09473684430122375)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.10526315867900848)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.11578948050737381)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (12): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.12631580233573914)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (13): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.13684210181236267)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (14): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.1473684310913086)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (15): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.15789474546909332)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (16): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.16842105984687805)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (17): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.17894737422466278)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (18): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.1894736886024475)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (19): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.20000001788139343)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (20): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.21052631735801697)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (21): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.2210526466369629)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (22): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.23157896101474762)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (23): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.24210527539253235)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (24): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.2526315748691559)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (25): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.2631579041481018)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (26): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.27368420362472534)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (27): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.28421053290367126)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (28): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.2947368323802948)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (29): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.3052631616592407)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (30): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.31578946113586426)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (31): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.3263157904148102)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (32): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.3368421196937561)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (33): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.34736841917037964)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (34): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.35789474844932556)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (35): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.3684210479259491)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (36): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.378947377204895)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (37): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.38947367668151855)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (38): Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): DropPath(p=0.4000000059604645)\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_ve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea0bf481",
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_config_hv = {'hidden_dropout_prob':0.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed66c578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c0bd8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e37a456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7371176b48d744c4a82debc4ee65c5ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc6dfb92b6294440adf8a6a634076704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hvit = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393c1169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18b1d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03281c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e29023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcae15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_config = Blip2VisionConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f85b095",
   "metadata": {},
   "outputs": [],
   "source": [
    "blip_ve = Blip2VisionModel(vision_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "997dd884",
   "metadata": {},
   "outputs": [],
   "source": [
    "or_bve = copy.deepcopy(blip_ve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "637676a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export http_proxy=http://oversea-squid4.sgp.txyun:11080 https_proxy=http://oversea-squid4.sgp.txyun:11080 no_proxy=localhost,127.0.0.1,localaddress,localdomain.com,internal,corp.kuaishou.com,test.gifshow.com,staging.kuaishou.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e55effbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/hetu_group/wangyan/envs/env_minigpt4/lib/python3.9/site-packages/transformers/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">hub.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">417</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cached_file</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 414 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>user_agent = http_user_agent(user_agent)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 415 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 416 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Load from URL or cache if already cached</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 417 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>resolved_file = hf_hub_download(                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 418 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>path_or_repo_id,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 419 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>filename,                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 420 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>subfolder=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(subfolder) == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> subfolder,                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/hetu_group/wangyan/envs/env_minigpt4/lib/python3.9/site-packages/huggingface_hub/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_validat</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ors.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">118</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_fn</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> check_use_auth_token:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span>, has_token=ha   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>118 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> fn(*args, **kwargs)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">119 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">120 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _inner_fn  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore</span>                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/hetu_group/wangyan/envs/env_minigpt4/lib/python3.9/site-packages/huggingface_hub/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">file_download.</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1291</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">hf_hub_download</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1288 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\" and downloads online, set 'local_files_only' to False.\"</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1289 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1290 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1291 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> LocalEntryNotFoundError(                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1292 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"Connection error, and we cannot find the requested files in\"</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1293 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\" the disk cache. Please try again or make sure your Internet\"</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1294 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\" connection is on.\"</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">LocalEntryNotFoundError: </span>Connection error, and we cannot find the requested files in the disk cache. Please try \n",
       "again or make sure your Internet connection is on.\n",
       "\n",
       "<span style=\"font-style: italic\">During handling of the above exception, another exception occurred:</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 automodel = AutoModelForImageClassification.from_pretrained(                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>pretrained_model_name_or_path = <span style=\"color: #808000; text-decoration-color: #808000\">\"google/vit-base-patch16-224-in21k\"</span>,  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># provide this</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>)                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/hetu_group/wangyan/envs/env_minigpt4/lib/python3.9/site-packages/transformers/models/auto/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">auto_</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">factory.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">456</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">453 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> kwargs.get(<span style=\"color: #808000; text-decoration-color: #808000\">\"torch_dtype\"</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>) == <span style=\"color: #808000; text-decoration-color: #808000\">\"auto\"</span>:                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">454 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>_ = kwargs.pop(<span style=\"color: #808000; text-decoration-color: #808000\">\"torch_dtype\"</span>)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">455 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>456 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>config, kwargs = AutoConfig.from_pretrained(                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">457 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>pretrained_model_name_or_path,                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">458 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>return_unused_kwargs=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>,                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">459 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>trust_remote_code=trust_remote_code,                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/hetu_group/wangyan/envs/env_minigpt4/lib/python3.9/site-packages/transformers/models/auto/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">confi</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">guration_auto.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">947</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">944 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>kwargs[<span style=\"color: #808000; text-decoration-color: #808000\">\"_from_auto\"</span>] = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">945 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>kwargs[<span style=\"color: #808000; text-decoration-color: #808000\">\"name_or_path\"</span>] = pretrained_model_name_or_path                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">946 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>trust_remote_code = kwargs.pop(<span style=\"color: #808000; text-decoration-color: #808000\">\"trust_remote_code\"</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>947 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_n   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">948 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>has_remote_code = <span style=\"color: #808000; text-decoration-color: #808000\">\"auto_map\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> config_dict <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"AutoConfig\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> config_dict[<span style=\"color: #808000; text-decoration-color: #808000\">\"aut</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">949 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>has_local_code = <span style=\"color: #808000; text-decoration-color: #808000\">\"model_type\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> config_dict <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> config_dict[<span style=\"color: #808000; text-decoration-color: #808000\">\"model_type\"</span>] <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> CO   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">950 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>trust_remote_code = resolve_trust_remote_code(                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/hetu_group/wangyan/envs/env_minigpt4/lib/python3.9/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">configuration_uti</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ls.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">574</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_config_dict</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">571 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">572 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>original_kwargs = copy.deepcopy(kwargs)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">573 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Get config dict associated with the base config file</span>                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>574 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>config_dict, kwargs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>._get_config_dict(pretrained_model_name_or_path, **kwar   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">575 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"_commit_hash\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> config_dict:                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">576 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>original_kwargs[<span style=\"color: #808000; text-decoration-color: #808000\">\"_commit_hash\"</span>] = config_dict[<span style=\"color: #808000; text-decoration-color: #808000\">\"_commit_hash\"</span>]                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">577 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/hetu_group/wangyan/envs/env_minigpt4/lib/python3.9/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">configuration_uti</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ls.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">629</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_config_dict</span>                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">626 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">627 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">628 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Load from local folder or from cache or download from model Hub and ca</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>629 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>resolved_config_file = cached_file(                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">630 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>pretrained_model_name_or_path,                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">631 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>configuration_file,                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">632 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>cache_dir=cache_dir,                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/hetu_group/wangyan/envs/env_minigpt4/lib/python3.9/site-packages/transformers/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">hub.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">452</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cached_file</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 449 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> resolved_file                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 450 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> _raise_exceptions_for_missing_entries <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> _raise_exceptions_for_connec  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 451 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 452 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">EnvironmentError</span>(                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 453 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"We couldn't connect to '{</span>HUGGINGFACE_CO_RESOLVE_ENDPOINT<span style=\"color: #808000; text-decoration-color: #808000\">}' to load this fi</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 454 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\" cached files and it looks like {</span>path_or_repo_id<span style=\"color: #808000; text-decoration-color: #808000\">} is not the path to a dir</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 455 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\" {</span>full_filename<span style=\"color: #808000; text-decoration-color: #808000\">}.\\nCheckout your internet connection or see how to run the</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OSError: </span>We couldn't connect to <span style=\"color: #008000; text-decoration-color: #008000\">'https://huggingface.co'</span> to load this file, couldn't find it in the cached files \n",
       "and it looks like google/vit-base-patch16-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224</span>-in21k is not the path to a directory containing a file named \n",
       "config.json.\n",
       "Checkout your internet connection or see how to run the library in offline mode at \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'https://huggingface.co/docs/transformers/installation#offline-mode'</span>.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/hetu_group/wangyan/envs/env_minigpt4/lib/python3.9/site-packages/transformers/utils/\u001b[0m\u001b[1;33mhub.py\u001b[0m:\u001b[94m417\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mcached_file\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 414 \u001b[0m\u001b[2m│   \u001b[0muser_agent = http_user_agent(user_agent)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 415 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mtry\u001b[0m:                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 416 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Load from URL or cache if already cached\u001b[0m                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 417 \u001b[2m│   │   \u001b[0mresolved_file = hf_hub_download(                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 418 \u001b[0m\u001b[2m│   │   │   \u001b[0mpath_or_repo_id,                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 419 \u001b[0m\u001b[2m│   │   │   \u001b[0mfilename,                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 420 \u001b[0m\u001b[2m│   │   │   \u001b[0msubfolder=\u001b[94mNone\u001b[0m \u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(subfolder) == \u001b[94m0\u001b[0m \u001b[94melse\u001b[0m subfolder,                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/hetu_group/wangyan/envs/env_minigpt4/lib/python3.9/site-packages/huggingface_hub/utils/\u001b[0m\u001b[1;33m_validat\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mors.py\u001b[0m:\u001b[94m118\u001b[0m in \u001b[92m_inner_fn\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m check_use_auth_token:                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[91m__name__\u001b[0m, has_token=ha   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m118 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m fn(*args, **kwargs)                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m119 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m120 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m _inner_fn  \u001b[2m# type: ignore\u001b[0m                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m121 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/hetu_group/wangyan/envs/env_minigpt4/lib/python3.9/site-packages/huggingface_hub/\u001b[0m\u001b[1;33mfile_download.\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mpy\u001b[0m:\u001b[94m1291\u001b[0m in \u001b[92mhf_hub_download\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1288 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m and downloads online, set \u001b[0m\u001b[33m'\u001b[0m\u001b[33mlocal_files_only\u001b[0m\u001b[33m'\u001b[0m\u001b[33m to False.\u001b[0m\u001b[33m\"\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1289 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1290 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1291 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m LocalEntryNotFoundError(                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1292 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mConnection error, and we cannot find the requested files in\u001b[0m\u001b[33m\"\u001b[0m             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1293 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m the disk cache. Please try again or make sure your Internet\u001b[0m\u001b[33m\"\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1294 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m connection is on.\u001b[0m\u001b[33m\"\u001b[0m                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mLocalEntryNotFoundError: \u001b[0mConnection error, and we cannot find the requested files in the disk cache. Please try \n",
       "again or make sure your Internet connection is on.\n",
       "\n",
       "\u001b[3mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
       "\n",
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 automodel = AutoModelForImageClassification.from_pretrained(                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m\u001b[2m│   \u001b[0mpretrained_model_name_or_path = \u001b[33m\"\u001b[0m\u001b[33mgoogle/vit-base-patch16-224-in21k\u001b[0m\u001b[33m\"\u001b[0m,  \u001b[2m# provide this\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0m)                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/hetu_group/wangyan/envs/env_minigpt4/lib/python3.9/site-packages/transformers/models/auto/\u001b[0m\u001b[1;33mauto_\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mfactory.py\u001b[0m:\u001b[94m456\u001b[0m in \u001b[92mfrom_pretrained\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m453 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m kwargs.get(\u001b[33m\"\u001b[0m\u001b[33mtorch_dtype\u001b[0m\u001b[33m\"\u001b[0m, \u001b[94mNone\u001b[0m) == \u001b[33m\"\u001b[0m\u001b[33mauto\u001b[0m\u001b[33m\"\u001b[0m:                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m454 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m_ = kwargs.pop(\u001b[33m\"\u001b[0m\u001b[33mtorch_dtype\u001b[0m\u001b[33m\"\u001b[0m)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m455 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m456 \u001b[2m│   │   │   \u001b[0mconfig, kwargs = AutoConfig.from_pretrained(                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m457 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mpretrained_model_name_or_path,                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m458 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mreturn_unused_kwargs=\u001b[94mTrue\u001b[0m,                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m459 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mtrust_remote_code=trust_remote_code,                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/hetu_group/wangyan/envs/env_minigpt4/lib/python3.9/site-packages/transformers/models/auto/\u001b[0m\u001b[1;33mconfi\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mguration_auto.py\u001b[0m:\u001b[94m947\u001b[0m in \u001b[92mfrom_pretrained\u001b[0m                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m944 \u001b[0m\u001b[2m│   │   \u001b[0mkwargs[\u001b[33m\"\u001b[0m\u001b[33m_from_auto\u001b[0m\u001b[33m\"\u001b[0m] = \u001b[94mTrue\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m945 \u001b[0m\u001b[2m│   │   \u001b[0mkwargs[\u001b[33m\"\u001b[0m\u001b[33mname_or_path\u001b[0m\u001b[33m\"\u001b[0m] = pretrained_model_name_or_path                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m946 \u001b[0m\u001b[2m│   │   \u001b[0mtrust_remote_code = kwargs.pop(\u001b[33m\"\u001b[0m\u001b[33mtrust_remote_code\u001b[0m\u001b[33m\"\u001b[0m, \u001b[94mNone\u001b[0m)                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m947 \u001b[2m│   │   \u001b[0mconfig_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_n   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m948 \u001b[0m\u001b[2m│   │   \u001b[0mhas_remote_code = \u001b[33m\"\u001b[0m\u001b[33mauto_map\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m config_dict \u001b[95mand\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mAutoConfig\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m config_dict[\u001b[33m\"\u001b[0m\u001b[33maut\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m949 \u001b[0m\u001b[2m│   │   \u001b[0mhas_local_code = \u001b[33m\"\u001b[0m\u001b[33mmodel_type\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m config_dict \u001b[95mand\u001b[0m config_dict[\u001b[33m\"\u001b[0m\u001b[33mmodel_type\u001b[0m\u001b[33m\"\u001b[0m] \u001b[95min\u001b[0m CO   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m950 \u001b[0m\u001b[2m│   │   \u001b[0mtrust_remote_code = resolve_trust_remote_code(                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/hetu_group/wangyan/envs/env_minigpt4/lib/python3.9/site-packages/transformers/\u001b[0m\u001b[1;33mconfiguration_uti\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mls.py\u001b[0m:\u001b[94m574\u001b[0m in \u001b[92mget_config_dict\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m571 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m572 \u001b[0m\u001b[2m│   │   \u001b[0moriginal_kwargs = copy.deepcopy(kwargs)                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m573 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Get config dict associated with the base config file\u001b[0m                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m574 \u001b[2m│   │   \u001b[0mconfig_dict, kwargs = \u001b[96mcls\u001b[0m._get_config_dict(pretrained_model_name_or_path, **kwar   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m575 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m config_dict:                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m576 \u001b[0m\u001b[2m│   │   │   \u001b[0moriginal_kwargs[\u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m] = config_dict[\u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m]                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m577 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/hetu_group/wangyan/envs/env_minigpt4/lib/python3.9/site-packages/transformers/\u001b[0m\u001b[1;33mconfiguration_uti\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mls.py\u001b[0m:\u001b[94m629\u001b[0m in \u001b[92m_get_config_dict\u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m626 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m627 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m628 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# Load from local folder or from cache or download from model Hub and ca\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m629 \u001b[2m│   │   │   │   \u001b[0mresolved_config_file = cached_file(                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m630 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mpretrained_model_name_or_path,                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m631 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mconfiguration_file,                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m632 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mcache_dir=cache_dir,                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/hetu_group/wangyan/envs/env_minigpt4/lib/python3.9/site-packages/transformers/utils/\u001b[0m\u001b[1;33mhub.py\u001b[0m:\u001b[94m452\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mcached_file\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 449 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m resolved_file                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 450 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m _raise_exceptions_for_missing_entries \u001b[95mor\u001b[0m \u001b[95mnot\u001b[0m _raise_exceptions_for_connec  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 451 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[94mNone\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 452 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mEnvironmentError\u001b[0m(                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 453 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mWe couldn\u001b[0m\u001b[33m'\u001b[0m\u001b[33mt connect to \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m to load this fi\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 454 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m cached files and it looks like \u001b[0m\u001b[33m{\u001b[0mpath_or_repo_id\u001b[33m}\u001b[0m\u001b[33m is not the path to a dir\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 455 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m \u001b[0m\u001b[33m{\u001b[0mfull_filename\u001b[33m}\u001b[0m\u001b[33m.\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33mCheckout your internet connection or see how to run the\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mOSError: \u001b[0mWe couldn't connect to \u001b[32m'https://huggingface.co'\u001b[0m to load this file, couldn't find it in the cached files \n",
       "and it looks like google/vit-base-patch16-\u001b[1;36m224\u001b[0m-in21k is not the path to a directory containing a file named \n",
       "config.json.\n",
       "Checkout your internet connection or see how to run the library in offline mode at \n",
       "\u001b[32m'https://huggingface.co/docs/transformers/installation#offline-mode'\u001b[0m.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "automodel = AutoModelForImageClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path = \"google/vit-base-patch16-224-in21k\",  # provide this in case you're planning to fine-tune an already fine-tuned checkpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce277793",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Blip2VisionConfig {\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"dropout\": 0.0,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_size\": 1408,\n",
       "  \"image_size\": 224,\n",
       "  \"initializer_factor\": 1.0,\n",
       "  \"initializer_range\": 1e-10,\n",
       "  \"intermediate_size\": 6144,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"model_type\": \"blip_2_vision_model\",\n",
       "  \"num_attention_heads\": 16,\n",
       "  \"num_channels\": 3,\n",
       "  \"num_hidden_layers\": 39,\n",
       "  \"patch_size\": 14,\n",
       "  \"projection_dim\": 512,\n",
       "  \"qkv_bias\": true,\n",
       "  \"transformers_version\": \"4.31.0.dev0\"\n",
       "}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vision_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b736ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69654b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
